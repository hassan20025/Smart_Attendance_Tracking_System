{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55eef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from torchvision import transforms\n",
    "from ultralytics import YOLO\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from scipy.spatial.distance import cosine\n",
    "import logging\n",
    "import torchvision.transforms.functional as TF\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f045bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load YAML configuration\n",
    "with open(\"config(avg).yaml\", \"r\") as f:\n",
    "    CONFIG = yaml.safe_load(f)\n",
    "\n",
    "def hex_to_bgr(hex_color):\n",
    "    \"\"\"Convert hex color to BGR tuple\"\"\"\n",
    "    hex_color = hex_color.lstrip(\"#\")\n",
    "    r, g, b = int(hex_color[0:2], 16), int(hex_color[2:4], 16), int(hex_color[4:6], 16)\n",
    "    return (b, g, r)\n",
    "\n",
    "# Convert yolo_input_size list to tuple\n",
    "CONFIG[\"yolo_input_size\"] = tuple(CONFIG[\"yolo_input_size\"])\n",
    "\n",
    "# Convert padding_color from hex to BGR\n",
    "CONFIG[\"padding_color\"] = hex_to_bgr(CONFIG[\"padding_color\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    \"\"\"Load YOLOv11 and FaceNet\"\"\"\n",
    "    try:\n",
    "        yolo = YOLO(CONFIG[\"model_paths\"][\"yolo\"]).eval()\n",
    "        facenet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "        facenet.to(device)\n",
    "        return yolo, facenet, device\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading models: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea7e810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(frame, model):\n",
    "    \"\"\"Detect faces using YOLO\"\"\"\n",
    "    try:\n",
    "        results = model(frame)\n",
    "        boxes = []\n",
    "        for result in results[0].boxes:\n",
    "            x1, y1, x2, y2 = map(int, result.xyxy[0])\n",
    "            conf = float(result.conf[0])\n",
    "            cls = int(result.cls[0])\n",
    "            if conf > CONFIG[\"detection_threshold\"] and cls == 0:  # Class 0 = Person\n",
    "                boxes.append((x1, y1, x2, y2))\n",
    "        return boxes\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error detecting faces: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(face_imgs, model, device):\n",
    "    ##Extract 512D embeddings from multiple face images (batch processing)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((160, 160)),\n",
    "        transforms.Normalize([0.5] * 3, [0.5] * 3)\n",
    "    ])\n",
    "    \n",
    "    if not face_imgs:  # Handle empty face_imgs case\n",
    "        logging.debug(\"No face images provided for embedding extraction\")\n",
    "        return np.array([])  # Return empty NumPy array\n",
    "    \n",
    "    try:\n",
    "        tensors = torch.stack([transform(Image.fromarray(face_img)) for face_img in face_imgs]).to(device)\n",
    "        with torch.no_grad():\n",
    "            embs = model(tensors)\n",
    "        embs = embs / embs.norm(p=2, dim=1, keepdim=True)\n",
    "        return embs.cpu().numpy()  # Still return NumPy array for compatibility\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting embeddings: {e}\")\n",
    "        return np.array([])  # Return empty NumPy array on error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf267f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_scores(embedding, stored, device):\n",
    "    #Compare new embedding with each person's stored embeddings using GPU\n",
    "    similarities = {}\n",
    "    # Convert input embedding to a PyTorch tensor on the specified device\n",
    "    embedding_tensor = torch.tensor(embedding, dtype=torch.float32, device=device)\n",
    "    embedding_tensor = embedding_tensor / embedding_tensor.norm(p=2, dim=-1, keepdim=True)\n",
    "    \n",
    "    for name, embeds in stored.items():\n",
    "        # Convert stored embeddings to a PyTorch tensor on the device\n",
    "        embeds_tensor = torch.tensor(embeds, dtype=torch.float32, device=device)\n",
    "        embeds_tensor = embeds_tensor / embeds_tensor.norm(p=2, dim=-1, keepdim=True)\n",
    "        \n",
    "        # Compute cosine similarity (1 - cosine distance) on GPU\n",
    "        scores = torch.matmul(embeds_tensor, embedding_tensor).cpu().numpy()\n",
    "        similarities[name] = round(float(np.mean(scores)), 4)\n",
    "    \n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac99543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_image_box(frame, x1, y1, x2, y2, name, box_img):\n",
    "    \"\"\"Draw bounding box and label on frame\"\"\"\n",
    "    box_width, box_height = x2 - x1, y2 - y1\n",
    "    overlay_image_alpha(frame, box_img, x1, y1, (box_width, box_height))\n",
    "\n",
    "    try:\n",
    "        person_name, student_id = name.split(\"_\", 1)\n",
    "    except ValueError:\n",
    "        person_name, student_id = name, \"N/A\"\n",
    "\n",
    "    label = f\"Name: {person_name}\\nID: {student_id}\"\n",
    "\n",
    "    font_path = CONFIG[\"model_paths\"].get(\"font_path\", \"\")\n",
    "    try:\n",
    "        font = ImageFont.truetype(font_path, 20)\n",
    "    except Exception:\n",
    "        logging.warning(\"Font not found. Falling back to default.\")\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    img_pil = Image.fromarray(frame)\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "\n",
    "    lines = label.split(\"\\n\")\n",
    "    line_height = 25\n",
    "    total_text_height = len(lines) * line_height\n",
    "    label_x, label_y = x1, y1 - total_text_height - 1\n",
    "\n",
    "    hex_color = CONFIG[\"label_color\"]\n",
    "    label_color = tuple(int(hex_color[i:i+2], 16) for i in (1, 3, 5))\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        draw.text((label_x, label_y + i * line_height), line, font=font, fill=label_color)\n",
    "\n",
    "    return np.array(img_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f97036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_image_alpha(background, overlay, x, y, overlay_size=None):\n",
    "    \"\"\"Draw image with transparency\"\"\"\n",
    "    if overlay_size:\n",
    "        overlay = cv2.resize(overlay, overlay_size)\n",
    "    h, w = overlay.shape[:2]\n",
    "    if y + h > background.shape[0] or x + w > background.shape[1]:\n",
    "        return\n",
    "    overlay_img = overlay[:, :, :3]\n",
    "    mask = overlay[:, :, 3:] / 255.0\n",
    "    background_crop = background[y:y+h, x:x+w]\n",
    "    background[y:y+h, x:x+w] = (1 - mask) * background_crop + mask * overlay_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0422d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rounded_rect(img, top_left, bottom_right, radius, color):\n",
    "    \"\"\"Draw a rounded rectangle on the image\"\"\"\n",
    "    x1, y1 = top_left\n",
    "    x2, y2 = bottom_right\n",
    "    rect_w, rect_h = x2 - x1, y2 - y1\n",
    "    rounded_rect = np.zeros((rect_h, rect_w, 4), dtype=np.uint8)\n",
    "    cv2.rectangle(rounded_rect, (radius, 0), (rect_w - radius, rect_h), (*color, 255), -1)\n",
    "    cv2.rectangle(rounded_rect, (0, radius), (rect_w, rect_h - radius), (*color, 255), -1)\n",
    "    for cx, cy in [(radius, radius), (rect_w-radius, radius), (radius, rect_h-radius), (rect_w-radius, rect_h-radius)]:\n",
    "        cv2.circle(rounded_rect, (cx, cy), radius, (*color, 255), -1)\n",
    "    mask = rounded_rect[:, :, 3] / 255.0\n",
    "    for c in range(3):\n",
    "        img[y1:y2, x1:x2, c] = mask * rounded_rect[:, :, c] + (1 - mask) * img[y1:y2, x1:x2, c]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a15c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_logo(base_img, logo_img, pos):\n",
    "    \"\"\"Overlay a logo with transparency\"\"\"\n",
    "    x, y = pos\n",
    "    h, w = logo_img.shape[:2]\n",
    "    if y + h > base_img.shape[0] or x + w > base_img.shape[1]:\n",
    "        return base_img\n",
    "    if logo_img.shape[2] == 4:\n",
    "        alpha_s = logo_img[:, :, 3] / 255.0\n",
    "        alpha_l = 1.0 - alpha_s\n",
    "        for c in range(3):\n",
    "            base_img[y:y+h, x:x+w, c] = alpha_s * logo_img[:, :, c] + alpha_l * base_img[y:y+h, x:x+w, c]\n",
    "    else:\n",
    "        base_img[y:y+h, x:x+w] = logo_img\n",
    "    return base_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_csv(stored_embeddings):\n",
    "    \"\"\"Create CSV with all students marked as Absent\"\"\"\n",
    "    csv_data = []\n",
    "    date = time.strftime(\"%Y-%m-%d\")\n",
    "    for name in stored_embeddings.keys():\n",
    "        csv_data.append([name, \"Absent\", date, \"\"])\n",
    "    return csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a8fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def get_csv_filename():\n",
    "    now = time.localtime()\n",
    "    hour = now.tm_hour\n",
    "    if hour == 0:  # Midnight: belongs to previous day's 11PM-12:59AM block\n",
    "        prev_day = time.localtime(time.mktime(now) - 86400)\n",
    "        date_str = time.strftime(\"%Y-%m-%d\", prev_day)\n",
    "        start_hour = 23\n",
    "    else:\n",
    "        date_str = time.strftime(\"%Y-%m-%d\", now)\n",
    "        if hour % 2 == 0:\n",
    "            start_hour = hour - 1\n",
    "        else:\n",
    "            start_hour = hour\n",
    "    am_pm = \"AM\" if start_hour < 12 else \"PM\"\n",
    "    display_hour = start_hour if start_hour <= 12 else start_hour - 12\n",
    "    if display_hour == 0:\n",
    "        display_hour = 12\n",
    "    return f\"{date_str}_session_{display_hour}{am_pm}.csv\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_filename():\n",
    "    return \"Attendance Sheet.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622be798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_attendance(name, attendance_logged, csv_data):\n",
    "    \"\"\"Mark student as present in CSV if not already marked\"\"\"\n",
    "    if name == \"Unknown\":\n",
    "        return\n",
    "    if name in attendance_logged:\n",
    "        return\n",
    "    date, clock = time.strftime(\"%Y-%m-%d\"), time.strftime(\"%H:%M:%S\")\n",
    "    for row in csv_data:\n",
    "        if row[0] == name:\n",
    "            row[1] = \"Attend\"\n",
    "            row[2] = date\n",
    "            row[3] = clock\n",
    "    attendance_logged.add(name)\n",
    "    logging.info(f\"[{date} {clock}] Marked: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff014387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_attendance_session():\n",
    "   # Main function to run the attendance session with timer and fixed 1280x720 camera feed\n",
    "    yolo, facenet, device = load_models()\n",
    "\n",
    "    with open(CONFIG[\"model_paths\"][\"embeddings\"], \"rb\") as f:\n",
    "        stored_embeddings = pickle.load(f)\n",
    "\n",
    "    box_img = cv2.imread(CONFIG[\"model_paths\"][\"box_img\"], cv2.IMREAD_UNCHANGED)\n",
    "    logo_left = cv2.imread(CONFIG[\"model_paths\"][\"logo_left_path\"], cv2.IMREAD_UNCHANGED)\n",
    "    logo_right = cv2.imread(CONFIG[\"model_paths\"][\"logo_right_path\"], cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    vote_tracker = {}\n",
    "    attendance_logged = set()\n",
    "    csv_data = initialize_csv(stored_embeddings)\n",
    "\n",
    "    ### Hikvision\n",
    "    \"\"\"\n",
    "    # Initialize RTSP camera\n",
    "    rtsp_url = \"rtsp://admin:Starthassan%402002@192.168.1.64/Streaming/Channels/101\"\n",
    "    cap = cv2.VideoCapture(rtsp_url)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        logging.error(\"Could not open camera. Check RTSP URL or camera connection.\")\n",
    "        return\n",
    "    # Use native camera resolution\n",
    "    cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'H264'))\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 4)\n",
    "    \"\"\"\n",
    "####\n",
    "\n",
    "#### webcam\n",
    "    cap = cv2.VideoCapture(0)  \n",
    "    if not cap.isOpened():\n",
    "        logging.error(\"Could not open webcam. Please check your device connection.\")\n",
    "        return\n",
    "####\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    logging.info(f\"Camera resolution: {width}x{height}\")\n",
    "\n",
    "    # Get screen resolution for full-screen display\n",
    "    screen_width = 1920  # Default\n",
    "    screen_height = 1080  # Default\n",
    "    try:\n",
    "        import tkinter as tk\n",
    "        root = tk.Tk()\n",
    "        screen_width = root.winfo_screenwidth()\n",
    "        screen_height = root.winfo_screenheight()\n",
    "        root.destroy()\n",
    "    except ImportError:\n",
    "        logging.warning(\"tkinter not available, using default screen size 1920x1080\")\n",
    "\n",
    "    # Set canvas size to fit 1280x720 feed plus padding\n",
    "    canvas_width = max(screen_width, 1280 + 2 * CONFIG[\"padding\"])\n",
    "    canvas_height = max(screen_height, 720 + 2 * CONFIG[\"padding\"])\n",
    "\n",
    "    # Set fixed camera feed size\n",
    "    camera_width = 1280\n",
    "    camera_height = 720\n",
    "    logging.info(f\"Camera feed UI size: {camera_width}x{camera_height}\")\n",
    "\n",
    "    # Scale logos\n",
    "    logo_left = cv2.resize(logo_left, (0, 0), fx=CONFIG[\"logo_size_percent_left\"], fy=CONFIG[\"logo_size_percent_left\"])\n",
    "    logo_right = cv2.resize(logo_right, (0, 0), fx=CONFIG[\"logo_size_percent_right\"], fy=CONFIG[\"logo_size_percent_right\"])\n",
    "\n",
    "    # Create full-screen window\n",
    "    cv2.namedWindow(\"Face Attendance\", cv2.WINDOW_FULLSCREEN)\n",
    "    cv2.setWindowProperty(\"Face Attendance\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "    yolo_input_width, yolo_input_height = CONFIG[\"yolo_input_size\"]\n",
    "    session_start_time = time.time()\n",
    "    logging.info(\"Press 'q' to end session.\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Check session timeout\n",
    "            elapsed_time = time.time() - session_start_time\n",
    "            if elapsed_time > CONFIG[\"session_timeout\"]:\n",
    "                logging.info(f\"Session timeout reached ({CONFIG['session_timeout']} seconds). Exiting session...\")\n",
    "                break\n",
    "\n",
    "            # Capture frame\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                logging.warning(\"Failed to read frame from camera\")\n",
    "                continue\n",
    "\n",
    "            start_time = time.time()\n",
    "            logging.debug(f\"Frame shape: {frame.shape}\")\n",
    "\n",
    "            # Resize frame for YOLO while preserving aspect ratio\n",
    "            orig_width, orig_height = frame.shape[1], frame.shape[0]\n",
    "            yolo_frame = cv2.resize(frame, (yolo_input_width, yolo_input_height))\n",
    "\n",
    "            # Detect faces on resized frame\n",
    "            boxes = detect_faces(yolo_frame, yolo)\n",
    "\n",
    "            # Scale bounding boxes back to original frame size\n",
    "            scale_x = orig_width / yolo_input_width\n",
    "            scale_y = orig_height / yolo_input_height\n",
    "            boxes = [(int(x1 * scale_x), int(y1 * scale_y), int(x2 * scale_x), int(y2 * scale_y))\n",
    "                     for x1, y1, x2, y2 in boxes]\n",
    "\n",
    "            # Extract face images from original frame\n",
    "            face_imgs = []\n",
    "            for x1, y1, x2, y2 in boxes:\n",
    "                face = frame[max(0, y1):y2, max(0, x1):x2]\n",
    "                if face.size == 0:\n",
    "                    continue\n",
    "                face_imgs.append(face)\n",
    "\n",
    "            # Extract embeddings\n",
    "            embeddings = extract_embeddings(face_imgs, facenet, device)\n",
    "\n",
    "            # Resize frame for display\n",
    "            display_frame = cv2.resize(frame, (camera_width, camera_height))\n",
    "\n",
    "            if len(embeddings) > 0:\n",
    "                # Scale bounding boxes to display frame size\n",
    "                scale_x = camera_width / orig_width\n",
    "                scale_y = camera_height / orig_height\n",
    "                display_boxes = [(int(x1 * scale_x), int(y1 * scale_y), int(x2 * scale_x), int(y2 * scale_y))\n",
    "                                 for x1, y1, x2, y2 in boxes]\n",
    "\n",
    "                for i, (x1, y1, x2, y2) in enumerate(display_boxes):\n",
    "                    embedding = embeddings[i]\n",
    "                    similarities = get_similarity_scores(embedding, stored_embeddings, device)  # Pass device\n",
    "\n",
    "                    logging.info(\"\\n--- Face Detected ---\")\n",
    "                    for name, score in sorted(similarities.items(), key=lambda x: x[1], reverse=True):\n",
    "                        logging.info(f\"{name}: {score:.4f}\")\n",
    "\n",
    "                    best_match = max(similarities, key=similarities.get)\n",
    "                    best_score = similarities[best_match]\n",
    "\n",
    "                    if best_score >= CONFIG[\"similarity_threshold\"]:\n",
    "                        vote_tracker[best_match] = vote_tracker.get(best_match, 0) + 1\n",
    "                        if vote_tracker[best_match] >= CONFIG[\"frame_threshold\"]:\n",
    "                            log_attendance(best_match, attendance_logged, csv_data)\n",
    "\n",
    "                    name = best_match if best_score >= CONFIG[\"similarity_threshold\"] else \"Unknown\"\n",
    "                    display_frame = draw_image_box(display_frame, x1, y1, x2, y2, name, box_img)\n",
    "\n",
    "            # Create canvas\n",
    "            canvas = np.full((canvas_height, canvas_width, 3), 255, dtype=np.uint8)\n",
    "            cam_x = (canvas_width - camera_width) // 2\n",
    "            cam_y = (canvas_height - camera_height) // 2\n",
    "\n",
    "            # Draw rounded rectangle padding\n",
    "            canvas = draw_rounded_rect(canvas,\n",
    "                                       (cam_x - CONFIG[\"padding\"], cam_y - CONFIG[\"padding\"]),\n",
    "                                       (cam_x + camera_width + CONFIG[\"padding\"], cam_y + camera_height + CONFIG[\"padding\"]),\n",
    "                                       CONFIG[\"corner_radius\"], CONFIG[\"padding_color\"])\n",
    "\n",
    "            # Place camera feed\n",
    "            canvas[cam_y:cam_y+camera_height, cam_x:cam_x+camera_width] = display_frame\n",
    "\n",
    "            # Overlay logos\n",
    "            canvas = overlay_logo(canvas, logo_left, (CONFIG[\"logo_margin_left\"], CONFIG[\"logo_margin_left\"]))\n",
    "            right_x = canvas_width - logo_right.shape[1] - CONFIG[\"logo_margin_right\"]\n",
    "            canvas = overlay_logo(canvas, logo_right, (right_x, CONFIG[\"logo_margin_right\"]))\n",
    "\n",
    "            # Draw FPS\n",
    "            end_time = time.time()\n",
    "            fps = 1 / (end_time - start_time)\n",
    "            cv2.putText(canvas, f\"FPS: {fps:.2f}\", (20, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "            cv2.imshow(\"Face Attendance\", canvas)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q') or key == ord('Q'):\n",
    "                logging.info(\"Exit key 'Q' pressed. Exiting session...\")\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \"\"\"\n",
    "        session_end_time = time.time()\n",
    "        duration = time.strftime(\"%H:%M:%S\", time.gmtime(session_end_time - session_start_time))\n",
    "        csv_data.append([\"Total Duration\", \"\", \"\", \"\", duration])\n",
    "        \"\"\"\n",
    "        csv_file = get_csv_filename()\n",
    "        with open(csv_file, \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            data_rows = [row for row in csv_data if row[1] != \"\" and row[1] != \"N/A\"]\n",
    "            footer_rows = [row for row in csv_data if row[1] == \"\" or row[1] == \"N/A\"]\n",
    "            data_rows.sort(key=lambda x: x[1])\n",
    "            writer.writerow([\"Student Name\", \"ID\", \"Status\", \"Date\", \"Time\"])\n",
    "            for row in data_rows:\n",
    "                name, student_id = row[0].split(\"_\", 1) if \"_\" in row[0] else (row[0], \"N/A\")\n",
    "                writer.writerow([name, student_id, row[1], row[2], row[3]])\n",
    "            writer.writerows(footer_rows)\n",
    "\n",
    "        logging.info(f\"Session ended. Attendance saved to: {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c06f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_attendance_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH_USING_GPU_CUDA_11_8_PYTHON_3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
