{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3403390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from torchvision import transforms\n",
    "from ultralytics import YOLO\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from scipy.spatial.distance import cosine\n",
    "import logging\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba9dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load YAML configuration\n",
    "with open(\"config(avg).yaml\", \"r\") as f:\n",
    "    CONFIG = yaml.safe_load(f)\n",
    "\n",
    "def hex_to_bgr(hex_color):\n",
    "    \"\"\"Convert hex color to BGR tuple\"\"\"\n",
    "    hex_color = hex_color.lstrip(\"#\")\n",
    "    r, g, b = int(hex_color[0:2], 16), int(hex_color[2:4], 16), int(hex_color[4:6], 16)\n",
    "    return (b, g, r)\n",
    "\n",
    "# Convert yolo_input_size list to tuple\n",
    "CONFIG[\"yolo_input_size\"] = tuple(CONFIG[\"yolo_input_size\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff40cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    \"\"\"Load YOLOv11 and FaceNet\"\"\"\n",
    "    try:\n",
    "        yolo = YOLO(CONFIG[\"model_paths\"][\"yolo\"]).eval()\n",
    "        facenet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "        facenet.to(device)\n",
    "        return yolo, facenet, device\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading models: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2245d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(frame, model):\n",
    "    \"\"\"Detect faces using YOLO\"\"\"\n",
    "    try:\n",
    "        results = model(frame)\n",
    "        boxes = []\n",
    "        for result in results[0].boxes:\n",
    "            x1, y1, x2, y2 = map(int, result.xyxy[0])\n",
    "            conf = float(result.conf[0])\n",
    "            cls = int(result.cls[0])\n",
    "            if conf > CONFIG[\"detection_threshold\"] and cls == 0:  # Class 0 = Person\n",
    "                boxes.append((x1, y1, x2, y2))\n",
    "        return boxes\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error detecting faces: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(face_imgs, model, device):\n",
    "    \"\"\"Extract 512D embeddings from multiple face images (batch processing)\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((160, 160)),\n",
    "        transforms.Normalize([0.5] * 3, [0.5] * 3)\n",
    "    ])\n",
    "    \n",
    "    if not face_imgs:  # Handle empty face_imgs case\n",
    "        logging.debug(\"No face images provided for embedding extraction\")\n",
    "        return np.array([])  # Return empty NumPy array\n",
    "    \n",
    "    try:\n",
    "        tensors = torch.stack([transform(Image.fromarray(face_img)) for face_img in face_imgs]).to(device)\n",
    "        with torch.no_grad():\n",
    "            embs = model(tensors)\n",
    "        embs = embs / embs.norm(p=2, dim=1, keepdim=True)\n",
    "        return embs.cpu().numpy()  # Still return NumPy array for compatibility\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting embeddings: {e}\")\n",
    "        return np.array([])  # Return empty NumPy array on error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ba7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_scores(embedding, stored, device):\n",
    "    \"\"\"Compare new embedding with each person's stored embeddings using GPU\"\"\"\n",
    "    similarities = {}\n",
    "    embedding_tensor = torch.tensor(embedding, dtype=torch.float32, device=device)\n",
    "    embedding_tensor = embedding_tensor / embedding_tensor.norm(p=2, dim=-1, keepdim=True)\n",
    "    \n",
    "    for name, embeds in stored.items():\n",
    "        embeds_tensor = torch.tensor(embeds, dtype=torch.float32, device=device)\n",
    "        embeds_tensor = embeds_tensor / embeds_tensor.norm(p=2, dim=-1, keepdim=True)\n",
    "        scores = torch.matmul(embeds_tensor, embedding_tensor).cpu().numpy()\n",
    "        similarities[name] = round(float(np.mean(scores)), 4)\n",
    "    \n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c91fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_image_box(frame, x1, y1, x2, y2, name, box_img):\n",
    "    \"\"\"Draw bounding box and label on frame\"\"\"\n",
    "    box_width, box_height = x2 - x1, y2 - y1\n",
    "    overlay_image_alpha(frame, box_img, x1, y1, (box_width, box_height))\n",
    "\n",
    "    try:\n",
    "        person_name, student_id = name.split(\"_\", 1)\n",
    "    except ValueError:\n",
    "        person_name, student_id = name, \"N/A\"\n",
    "\n",
    "    label = f\"Name: {person_name}\\nID: {student_id}\"\n",
    "\n",
    "    font_path = CONFIG[\"model_paths\"].get(\"font_path\", \"\")\n",
    "    try:\n",
    "        font = ImageFont.truetype(font_path, 20)\n",
    "    except Exception:\n",
    "        logging.warning(\"Font not found. Falling back to default.\")\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    img_pil = Image.fromarray(frame)\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "\n",
    "    lines = label.split(\"\\n\")\n",
    "    line_height = 25\n",
    "    total_text_height = len(lines) * line_height\n",
    "    label_x, label_y = x1, y1 - total_text_height - 1\n",
    "\n",
    "    hex_color = CONFIG[\"label_color\"]\n",
    "    label_color = tuple(int(hex_color[i:i+2], 16) for i in (1, 3, 5))\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        draw.text((label_x, label_y + i * line_height), line, font=font, fill=label_color)\n",
    "\n",
    "    return np.array(img_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_image_alpha(background, overlay, x, y, overlay_size=None):\n",
    "    \"\"\"Draw image with transparency\"\"\"\n",
    "    if overlay_size:\n",
    "        overlay = cv2.resize(overlay, overlay_size)\n",
    "    h, w = overlay.shape[:2]\n",
    "    if y + h > background.shape[0] or x + w > background.shape[1]:\n",
    "        return\n",
    "    overlay_img = overlay[:, :, :3]\n",
    "    mask = overlay[:, :, 3:] / 255.0\n",
    "    background_crop = background[y:y+h, x:x+w]\n",
    "    background[y:y+h, x:x+w] = (1 - mask) * background_crop + mask * overlay_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a57e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_csv(stored_embeddings):\n",
    "    \"\"\"Create CSV with all students marked as Absent\"\"\"\n",
    "    csv_data = []\n",
    "    date = time.strftime(\"%Y-%m-%d\")\n",
    "    for name in stored_embeddings.keys():\n",
    "        csv_data.append([name, \"Absent\", date, \"\"])\n",
    "    return csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e3a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def get_csv_filename():\n",
    "    Generate CSV filename based on session time\n",
    "    now = time.localtime()\n",
    "    hour = now.tm_hour\n",
    "    if hour == 0:  # Midnight: belongs to previous day's 11PM-12:59AM block\n",
    "        prev_day = time.localtime(time.mktime(now) - 86400)\n",
    "        date_str = time.strftime(\"%Y-%m-%d\", prev_day)\n",
    "        start_hour = 23\n",
    "    else:\n",
    "        date_str = time.strftime(\"%Y-%m-%d\", now)\n",
    "        if hour % 2 == 0:\n",
    "            start_hour = hour - 1\n",
    "        else:\n",
    "            start_hour = hour\n",
    "    am_pm = \"AM\" if start_hour < 12 else \"PM\"\n",
    "    display_hour = start_hour if start_hour <= 12 else start_hour - 12\n",
    "    if display_hour == 0:\n",
    "        display_hour = 12\n",
    "    return f\"{date_str}_session_{display_hour}{am_pm}.csv\"\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4c2a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_filename():\n",
    "    return \"Attendance Sheet.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca5071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_attendance(name, attendance_logged, csv_data):\n",
    "    \"\"\"Mark student as present in CSV if not already marked\"\"\"\n",
    "    if name == \"Unknown\":\n",
    "        return\n",
    "    if name in attendance_logged:\n",
    "        return\n",
    "    date, clock = time.strftime(\"%Y-%m-%d\"), time.strftime(\"%H:%M:%S\")\n",
    "    for row in csv_data:\n",
    "        if row[0] == name:\n",
    "            row[1] = \"Attend\"\n",
    "            row[2] = date\n",
    "            row[3] = clock\n",
    "    attendance_logged.add(name)\n",
    "    logging.info(f\"[{date} {clock}] Marked: {name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_attendance_session():\n",
    "    \"\"\"Main function to run the attendance session with only camera feed and smaller FPS\"\"\"\n",
    "    yolo, facenet, device = load_models()\n",
    "\n",
    "    with open(CONFIG[\"model_paths\"][\"embeddings\"], \"rb\") as f:\n",
    "        stored_embeddings = pickle.load(f)\n",
    "\n",
    "    box_img = cv2.imread(CONFIG[\"model_paths\"][\"box_img\"], cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    vote_tracker = {}\n",
    "    attendance_logged = set()\n",
    "    csv_data = initialize_csv(stored_embeddings)\n",
    "\n",
    "    ### Hikvision\n",
    "    \"\"\"\n",
    "    # Initialize RTSP camera\n",
    "    rtsp_url = \"rtsp://admin:Starthassan%402002@192.168.1.64/Streaming/Channels/101\"\n",
    "    cap = cv2.VideoCapture(rtsp_url)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        logging.error(\"Could not open camera. Check RTSP URL or camera connection.\")\n",
    "        return\n",
    "    # Use native camera resolution\n",
    "    cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'H264'))\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 4)\n",
    "    \"\"\"\n",
    "####\n",
    "\n",
    "#### webcam\n",
    "    cap = cv2.VideoCapture(0)  \n",
    "    if not cap.isOpened():\n",
    "        logging.error(\"Could not open webcam. Please check your device connection.\")\n",
    "        return\n",
    "####\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    logging.info(f\"Camera resolution: {width}x{height}\")\n",
    "\n",
    "    # Create window with normal size\n",
    "    cv2.namedWindow(\"Face Attendance\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # Optional: Set a fixed display size (uncomment to use)\n",
    "    # display_width, display_height = 1280, 720\n",
    "    # cv2.resizeWindow(\"Face Attendance\", display_width, display_height)\n",
    "\n",
    "    yolo_input_width, yolo_input_height = CONFIG[\"yolo_input_size\"]\n",
    "    session_start_time = time.time()\n",
    "    logging.info(\"Press 'q' to end session.\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Check session timeout\n",
    "            elapsed_time = time.time() - session_start_time\n",
    "            if elapsed_time > CONFIG[\"session_timeout\"]:\n",
    "                logging.info(f\"Session timeout reached ({CONFIG['session_timeout']} seconds). Exiting session...\")\n",
    "                break\n",
    "\n",
    "            # Capture frame\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                logging.warning(\"Failed to read frame from camera\")\n",
    "                continue\n",
    "\n",
    "            start_time = time.time()  # Start time for FPS calculation\n",
    "            logging.debug(f\"Frame shape: {frame.shape}\")\n",
    "\n",
    "            # Resize frame for YOLO while preserving aspect ratio\n",
    "            orig_width, orig_height = frame.shape[1], frame.shape[0]\n",
    "            yolo_frame = cv2.resize(frame, (yolo_input_width, yolo_input_height))\n",
    "\n",
    "            # Detect faces on resized frame\n",
    "            boxes = detect_faces(yolo_frame, yolo)\n",
    "\n",
    "            # Scale bounding boxes back to original frame size\n",
    "            scale_x = orig_width / yolo_input_width\n",
    "            scale_y = orig_height / yolo_input_height\n",
    "            boxes = [(int(x1 * scale_x), int(y1 * scale_y), int(x2 * scale_x), int(y2 * scale_y))\n",
    "                     for x1, y1, x2, y2 in boxes]\n",
    "\n",
    "            # Extract face images from original frame\n",
    "            face_imgs = []\n",
    "            for x1, y1, x2, y2 in boxes:\n",
    "                face = frame[max(0, y1):y2, max(0, x1):x2]\n",
    "                if face.size == 0:\n",
    "                    continue\n",
    "                face_imgs.append(face)\n",
    "\n",
    "            # Extract embeddings\n",
    "            embeddings = extract_embeddings(face_imgs, facenet, device)\n",
    "\n",
    "            if len(embeddings) > 0:\n",
    "                for i, (x1, y1, x2, y2) in enumerate(boxes):\n",
    "                    embedding = embeddings[i]\n",
    "                    similarities = get_similarity_scores(embedding, stored_embeddings, device)\n",
    "\n",
    "                    logging.info(\"\\n--- Face Detected ---\")\n",
    "                    for name, score in sorted(similarities.items(), key=lambda x: x[1], reverse=True):\n",
    "                        logging.info(f\"{name}: {score:.4f}\")\n",
    "\n",
    "                    best_match = max(similarities, key=similarities.get)\n",
    "                    best_score = similarities[best_match]\n",
    "\n",
    "                    if best_score >= CONFIG[\"similarity_threshold\"]:\n",
    "                        vote_tracker[best_match] = vote_tracker.get(best_match, 0) + 1\n",
    "                        if vote_tracker[best_match] >= CONFIG[\"frame_threshold\"]:\n",
    "                            log_attendance(best_match, attendance_logged, csv_data)\n",
    "\n",
    "                    name = best_match if best_score >= CONFIG[\"similarity_threshold\"] else \"Unknown\"\n",
    "                    frame = draw_image_box(frame, x1, y1, x2, y2, name, box_img)\n",
    "\n",
    "            # Draw smaller FPS on the frame\n",
    "            end_time = time.time()\n",
    "            fps = 1 / (end_time - start_time)\n",
    "            cv2.putText(frame, f\"FPS: {fps:.2f}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "            #  Resize frame for display (uncomment )\n",
    "            # frame = cv2.resize(frame, (display_width, display_height))\n",
    "\n",
    "            # Display the raw camera feed with bounding boxes, labels, and FPS\n",
    "            cv2.imshow(\"Face Attendance\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q') or key == ord('Q'):\n",
    "                logging.info(\"Exit key 'Q' pressed. Exiting session...\")\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        \"\"\"\n",
    "        session_end_time = time.time()\n",
    "        duration = time.strftime(\"%H:%M:%S\", time.gmtime(session_end_time - session_start_time))\n",
    "        csv_data.append([\"Total Duration\", \"\", \"\", \"\", duration])\n",
    "        \"\"\"\n",
    "        csv_file = get_csv_filename()\n",
    "        with open(csv_file, \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            data_rows = [row for row in csv_data if row[1] != \"\" and row[1] != \"N/A\"]\n",
    "            footer_rows = [row for row in csv_data if row[1] == \"\" or row[1] == \"N/A\"]\n",
    "            data_rows.sort(key=lambda x: x[1])\n",
    "            writer.writerow([\"Student Name\", \"ID\", \"Status\", \"Date\", \"Time\"])\n",
    "            for row in data_rows:\n",
    "                name, student_id = row[0].split(\"_\", 1) if \"_\" in row[0] else (row[0], \"N/A\")\n",
    "                writer.writerow([name, student_id, row[1], row[2], row[3]])\n",
    "            writer.writerows(footer_rows)\n",
    "\n",
    "        logging.info(f\"Session ended. Attendance saved to: {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea08fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_attendance_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH_USING_GPU_CUDA_11_8_PYTHON_3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
